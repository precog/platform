--- StandaloneActorEcosystem.scala	2012-05-15 10:37:20.000000000 -0600
+++ ProductionActorEcosystem.scala	2012-05-15 10:37:21.000000000 -0600
@@ -16,22 +16,48 @@
 
 import blueeyes.json.JsonAST._
 
-trait StandaloneActorEcosystem extends BaseActorEcosystem with Logging {
+trait ProductionActorConfig extends BaseConfig {
+  def shardId(): String = serviceUID.hostId + serviceUID.serviceId 
+
+  def kafkaHost(): String = config[String]("kafka.batch.host")
+  def kafkaPort(): Int = config[Int]("kafka.batch.port")
+  def kafkaTopic(): String = config[String]("kafka.batch.topic") 
+
+  def zookeeperHosts(): String = config[String]("zookeeper.hosts")
+  def zookeeperBase(): List[String] = config[List[String]]("zookeeper.basepath")
+  def zookeeperPrefix(): String = config[String]("zookeeper.prefix")   
+
+  def statusTimeout(): Long = config[Long]("actors.status.timeout", 30000)
+
+  def serviceUID(): ServiceUID = ZookeeperSystemCoordination.extractServiceUID(config)
+}
+
+trait ProductionActorEcosystem extends BaseActorEcosystem with Logging {
   type YggConfig <: ProductionActorConfig
   
   val pre = "[Yggdrasil Shard]"
 
-  lazy val actorSystem = ActorSystem("standalone_actor_system")
+  lazy val actorSystem = ActorSystem("production_actor_system")
+
+  lazy val routingActor = actorSystem.actorOf(Props(new BatchStoreActor(eventStore, 1000, Some(ingestActor), actorSystem.scheduler)), "router")
 
-  lazy val routingActor = actorSystem.actorOf(Props(new BatchStoreActor(eventStore, 1000, None, actorSystem.scheduler)), "router")
+  private lazy val actorsWithStatus = List(
+    projectionActors,
+    metadataActor,
+    routingActor,
+    ingestActor,
+    metadataSerializationActor
+  )
   
   def actorsStart() = Future[Unit] {
+    logger.info("Starting actor ecosystem")
     this.metadataSyncCancel
     routingActor ! Start
   }
   
-  def actorsStatus(): Future[JArray] = Future {
-    JArray(List(JString("StandaloneActorEcosystem status not yet implemented.")))
+  def actorsStatus(): Future[JArray] = {
+    implicit val to = Timeout(yggConfig.statusTimeout)
+    Future.sequence( actorsWithStatus.map { actor => (actor ? Status).mapTo[JValue] } ).map { JArray(_) }
   }
 
   def actorsStop(): Future[Unit] = {
@@ -71,6 +97,7 @@
             }
       _  <- routingActorStop
       _  <- flushMetadata
+      _  <- actorStop(ingestActor, "ingest")
       _  <- actorStop(projectionActors, "projection")
       _  <- actorStop(metadataActor, "metadata")
       _  <- actorStop(metadataSerializationActor, "flush")
@@ -88,18 +115,25 @@
   // Internal only actors
   //
   
+  private lazy val ingestActor = {
+    val ingestBatchConsumer = new KafkaBatchConsumer(yggConfig.kafkaHost, yggConfig.kafkaPort, yggConfig.kafkaTopic)
+    actorSystem.actorOf(Props(new KafkaShardIngestActor(checkpoints, ingestBatchConsumer)), "shard_ingest")
+  }
+ 
   private lazy val metadataSerializationActor = {
     val metadataStorage = new FilesystemMetadataStorage(yggState.descriptorLocator)
     actorSystem.actorOf(Props(new MetadataSerializationActor(checkpoints, metadataStorage)), "metadata_serializer")
   }
   
   private lazy val metadataSyncCancel = {
-    val metadataSyncPeriod = Duration(1, "minutes")
+    val metadataSyncPeriod = Duration(5, "minutes")
     actorSystem.scheduler.schedule(metadataSyncPeriod, metadataSyncPeriod, metadataActor, FlushMetadata(metadataSerializationActor))
   }
   
-  private lazy val checkpoints = new YggCheckpoints {
-    def saveRecoveryPoint(checkpoints: YggCheckpoint) { }
+  private lazy val checkpoints = {
+    val systemCoordination = ZookeeperSystemCoordination(yggConfig.zookeeperHosts, yggConfig.serviceUID) 
+    new SystemCoordinationYggCheckpoints(yggConfig.shardId, systemCoordination)
   }
 }
+
 // vim: set ts=4 sw=4 et:
